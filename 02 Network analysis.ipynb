{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from random import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import ast\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tweeter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"emotion_tweets_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create conections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = {}\n",
    "connections = {}\n",
    "\n",
    "x = df.sample(15000)\n",
    "\n",
    "for i,r in x.iterrows():\n",
    "    for pair in itertools.permutations(ast.literal_eval(r.hashtags),2):\n",
    "        \n",
    "        pair = sorted(pair)\n",
    "        \n",
    "        key = pair[0]+'&&'+pair[1]\n",
    "        \n",
    "        if key in inter:\n",
    "            inter[key]['i'] =inter[key]['i'] + 1\n",
    "            \n",
    "            if r.emotion in inter[key]['emotion']:\n",
    "                 inter[key]['emotion'][r.emotion] = inter[key]['emotion'][r.emotion] + 1\n",
    "            else:\n",
    "                inter[key]['emotion'][r.emotion] = 1\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            inter[key] = {'i':1, 'emotion':{r.emotion:1}}\n",
    "        \n",
    "        if pair[0] in connections:\n",
    "            connections[pair[0]] = connections[pair[0]] + 1\n",
    "        else:\n",
    "            connections[pair[0]] = 1\n",
    "            \n",
    "        if pair[1] in connections:\n",
    "            connections[pair[1]] = connections[pair[1]] + 1\n",
    "        else:\n",
    "            connections[pair[1]] = 1\n",
    "        \n",
    "        \n",
    "new_inter = {}\n",
    "for item in inter:\n",
    "    if  inter[item]['i'] > 1:\n",
    "        new_inter[item] = inter[item]\n",
    "        \n",
    "        \n",
    "# Get individual tags that were selected\n",
    "selHash = []\n",
    "for item in new_inter:\n",
    "    pair1 = item.split('&&')[0]\n",
    "    pair2 = item.split('&&')[1]\n",
    "    \n",
    "    if pair1 not in selHash: \n",
    "        selHash += [pair1]\n",
    "    if pair2 not in selHash: \n",
    "        selHash += [pair2]\n",
    "        \n",
    "\n",
    "df['t_interactions'] = df.nlikes + df.nreplies + df.nretweets\n",
    "\n",
    "interactions = []\n",
    "for i,r in df[df.t_interactions>0].iterrows():\n",
    "    hashs = ast.literal_eval(r.hashtags)\n",
    "    hashs = [(x,r.t_interactions) for x in  hashs]\n",
    "    \n",
    "    interactions += hashs\n",
    "    \n",
    "inter = pd.DataFrame(interactions,columns = ['tag','n']).groupby('tag',as_index =False).sum()    \n",
    "inter = dict(zip(inter.tag, inter.n))\n",
    "        \n",
    "\n",
    "# Get which emotion is more relevant for each sentiment\n",
    "emot = []\n",
    "for i,r in df.iterrows():\n",
    "    hashs = ast.literal_eval(r.hashtags)\n",
    "    hashs = [(x,r.emotion,1) for x in  hashs]\n",
    "    emot += hashs\n",
    "    \n",
    "emotions = pd.DataFrame(emot,columns = ['tag','emotion','n']).groupby(['tag','emotion'],as_index =False).count()  \n",
    "emotions = emotions.sort_values('n', ascending=False).drop_duplicates(['tag'])\n",
    "\n",
    "emotions_count = {}\n",
    "for i,r in emotions.iterrows():\n",
    "    emotions_count[r.tag] = {'emotion':r.emotion, 'n':r.n}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "plt.figure(3,figsize=(23,12)) \n",
    "\n",
    "for i in new_inter:\n",
    "    \n",
    "    G.add_edge(i.split('&&')[0],i.split('&&')[1], weight=new_inter[i]['i']/7)\n",
    "    \n",
    "colors  = {'joy':'tab:red','anger':'tab:blue','fear':'tab:green','trust':'tab:orange'}\n",
    "\n",
    "\n",
    "llaves = [x for x in G.nodes().keys() if G.degree[x] >100]\n",
    "llaves = [x for x in G.nodes().keys() ]\n",
    "\n",
    "\n",
    "included = []\n",
    "for edge in G.edges():\n",
    "    if len([i for i in list(edge) if i in llaves]) > 0:\n",
    "        included += list(edge)\n",
    "        \n",
    "llaves = pd.Series(llaves + included).unique().tolist()\n",
    "\n",
    "keys = list(G.nodes().keys())\n",
    "a= [ G.remove_node(key) for key in keys if key not in llaves]\n",
    "\n",
    "    \n",
    "weights = [0.1 for i in new_inter]\n",
    "sizes = [ (inter[node]/connections[node] + 30)**1.25  if node in inter and connections[node] > 6 else 10 for node in G.nodes()]\n",
    "color_map =  [ colors[emotions_count[node]['emotion']] if node in emotions_count else 'tab:gray' for node in G.nodes()]\n",
    "\n",
    "\n",
    "alpha_map = [ emotions_count[node]['n'] if node in emotions_count else 1 for node in G.nodes()]\n",
    "alpha_map = [ 0.05 + np.log(i)/13 for i in alpha_map]\n",
    "\n",
    "\n",
    "seeds =  ['#thankful','#feelinggood','#blessed','#happy','#estatic','#goodmood','#yay','#worstfear','#fear','#frightened',\n",
    "          '#worstfear','#fear','#frightened','#horror','#dismay','#anxious','#afraid',\n",
    "          '#horror','#dismay','#anxious','#afraid','#disappointed', '#angry','#mad','#pissed','#furious','#hate','#angrytweet'] \n",
    "\n",
    "\n",
    "seed_labels = {}\n",
    "new_labels = {}\n",
    "\n",
    "for node in G.degree:\n",
    "    if node[1]>10: \n",
    "        if node[0] in seeds:\n",
    "            seed_labels[node[0]] = node[0] \n",
    "        else:\n",
    "            new_labels[node[0]] = node[0] \n",
    "            \n",
    "popularity = {}\n",
    "for node in G.degree:\n",
    "    if (node[0] in inter):\n",
    "        if (inter[node[0]]/connections[node[0]] >25 and (connections[node[0]] > 10)) :\n",
    "            if (node[0] not in seeds ):\n",
    "                popularity[node[0]] = node[0] \n",
    "        \n",
    "popularity = {}\n",
    "for node in G.degree:\n",
    "    if (node[0] in inter):\n",
    "        if (inter[node[0]]/connections[node[0]] >25 and (connections[node[0]] > 10)) :\n",
    "            if (node[0] not in seeds ):\n",
    "                popularity[node[0]] = node[0] \n",
    "                \n",
    "                \n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "all = {}\n",
    "_ = [all.update({node[0]:node[0]})  for node in G.degree]\n",
    "\n",
    "nx.draw(G,  node_size = sizes,width=weights,node_color=color_map, alpha=0.70,with_labels=False, pos=pos)\n",
    "nx.draw_networkx_labels(G,pos, seed_labels,font_size=15,font_color='black',font_family='Tahoma',alpha=0.85,font_weight='bold');\n",
    "nx.draw_networkx_labels(G,pos, new_labels,font_size=19, font_color='darkred', family='Arial',alpha=0.95);\n",
    "nx.draw_networkx_labels(G,pos, popularity,font_size=19, font_color='darkblue', family='Arial',alpha=0.95);\n",
    "# nx.draw_networkx_labels(G,pos,all,font_size=19, font_color='darkblue', family='Arial',alpha=0.95);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
