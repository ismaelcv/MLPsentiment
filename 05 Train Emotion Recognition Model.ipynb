{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Emotion Recognition Model\n",
    "\n",
    "Here we'll train a emotion recognition model, using the output data from the sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project path to the PYTHONPATH\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ast\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM , GlobalAveragePooling1D, GlobalMaxPooling1D, Bidirectional, Conv1D, Dense, concatenate,MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from cleaning import cf\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load the emotion labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>nreplies</th>\n",
       "      <th>nretweets</th>\n",
       "      <th>search</th>\n",
       "      <th>emotion</th>\n",
       "      <th>lang</th>\n",
       "      <th>emoji</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28148</th>\n",
       "      <td>1124371022185140224</td>\n",
       "      <td>1556905916000</td>\n",
       "      <td>2019-05-03 12:51:56</td>\n",
       "      <td>realestateagent latoyaforbesgroup latoyalyonel...</td>\n",
       "      <td>['#blessed', '#realestateagent', '#latoyaforbe...</td>\n",
       "      <td>LatoyaUrRealtor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#trust</td>\n",
       "      <td>trust</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1224106016524197889</td>\n",
       "      <td>1580684591000</td>\n",
       "      <td>2020-02-02 18:03:11</td>\n",
       "      <td>people are afraid to make a change because the...</td>\n",
       "      <td>['#people', '#afraid', '#change', '#focus', '#...</td>\n",
       "      <td>MichelleAileene</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#afraid</td>\n",
       "      <td>fear</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14399</th>\n",
       "      <td>1011309671808811009</td>\n",
       "      <td>1529949989000</td>\n",
       "      <td>2018-06-25 13:06:29</td>\n",
       "      <td>black namaste white violent smile writers poet...</td>\n",
       "      <td>['#writers', '#poet', '#writer', '#spokenword'...</td>\n",
       "      <td>stiffmidlefinga</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#hate</td>\n",
       "      <td>anger</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19427</th>\n",
       "      <td>962439792674865153</td>\n",
       "      <td>1518298502000</td>\n",
       "      <td>2018-02-10 16:35:02</td>\n",
       "      <td>at the moment i m trying around with different...</td>\n",
       "      <td>['#drawing', '#scrapbooking', '#creepy', '#ske...</td>\n",
       "      <td>IICherubinaII</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#fear</td>\n",
       "      <td>fear</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>1070466884003344386</td>\n",
       "      <td>1544054168000</td>\n",
       "      <td>2018-12-05 18:56:08</td>\n",
       "      <td>thank you riesling always there for me when bo...</td>\n",
       "      <td>['#wine', '#thankful', '#sweaty', '#riesling',...</td>\n",
       "      <td>NKH3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#thankful</td>\n",
       "      <td>joy</td>\n",
       "      <td>en</td>\n",
       "      <td>[üôè, üôè, ü•∂, üî•]</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>979384672873603077</td>\n",
       "      <td>1522338476000</td>\n",
       "      <td>2018-03-29 10:47:56</td>\n",
       "      <td>strikes again left this outside in the rain ch...</td>\n",
       "      <td>['#angrytweet', '#hermes']</td>\n",
       "      <td>R_Leeee</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#angrytweet</td>\n",
       "      <td>anger</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16934</th>\n",
       "      <td>1127708795118018562</td>\n",
       "      <td>1557701703000</td>\n",
       "      <td>2019-05-12 17:55:03</td>\n",
       "      <td>join us for a wonderland tea party with alice ...</td>\n",
       "      <td>['#thekentuckycastle', '#tkcevents', '#castle'...</td>\n",
       "      <td>thecastlepost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#happy</td>\n",
       "      <td>joy</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15124</th>\n",
       "      <td>1021559301696049152</td>\n",
       "      <td>1532393691000</td>\n",
       "      <td>2018-07-23 19:54:51</td>\n",
       "      <td>the outcome of being without power for three d...</td>\n",
       "      <td>['#pissed', '#hungrynow']</td>\n",
       "      <td>KeMo_Allen76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#pissed</td>\n",
       "      <td>anger</td>\n",
       "      <td>en</td>\n",
       "      <td>[ü§¶, üèΩ, ‚ôÄ, üò†, ü§¶, üèΩ, ‚ôÄ]</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14493</th>\n",
       "      <td>1009877668198801408</td>\n",
       "      <td>1529608573000</td>\n",
       "      <td>2018-06-21 14:16:13</td>\n",
       "      <td>ihearya brave anxiety all shapes sizes gender ...</td>\n",
       "      <td>['#ihearya', '#brave', '#anxiety', '#anxious']</td>\n",
       "      <td>mrsroo83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#anxious</td>\n",
       "      <td>fear</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23201</th>\n",
       "      <td>1160303455212359680</td>\n",
       "      <td>1565472875000</td>\n",
       "      <td>2019-08-10 16:34:35</td>\n",
       "      <td>trust is choosing to make something important ...</td>\n",
       "      <td>['#vulnerability', '#trust', '#inspiration']</td>\n",
       "      <td>LeeMichaelWalt1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#trust</td>\n",
       "      <td>trust</td>\n",
       "      <td>en</td>\n",
       "      <td>[‚ú®, üïä]</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21250</th>\n",
       "      <td>1073309420791234560</td>\n",
       "      <td>1544731881000</td>\n",
       "      <td>2018-12-13 15:11:21</td>\n",
       "      <td>driving and you get stopped by every traffic l...</td>\n",
       "      <td>['#why', '#thursday', '#thursdaythoughts', '#a...</td>\n",
       "      <td>late_drinkers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>#angry</td>\n",
       "      <td>anger</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17010</th>\n",
       "      <td>1137848608483663872</td>\n",
       "      <td>1560119223000</td>\n",
       "      <td>2019-06-09 17:27:03</td>\n",
       "      <td>i met a new friend today and she sent me pictu...</td>\n",
       "      <td>['#art', '#blessed']</td>\n",
       "      <td>NymphaticM</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#blessed</td>\n",
       "      <td>joy</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13055</th>\n",
       "      <td>1216158136748429312</td>\n",
       "      <td>1578789669000</td>\n",
       "      <td>2020-01-11 19:41:09</td>\n",
       "      <td>how how could you end season like that release...</td>\n",
       "      <td>['#pissed', '#cliffhanger', '#finalspace']</td>\n",
       "      <td>ellendevenney96</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#pissed</td>\n",
       "      <td>anger</td>\n",
       "      <td>en</td>\n",
       "      <td>[üò≠]</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>1056786573914628096</td>\n",
       "      <td>1540792528000</td>\n",
       "      <td>2018-10-29 00:55:28</td>\n",
       "      <td>lmao igotbannedinroblox finally my lil brother...</td>\n",
       "      <td>['#lmao', '#yay', '#igotbannedinroblox']</td>\n",
       "      <td>bsg1623official</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#yay</td>\n",
       "      <td>joy</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>1112074032499904512</td>\n",
       "      <td>1553974085000</td>\n",
       "      <td>2019-03-30 14:28:05</td>\n",
       "      <td>my husband just confessed to me that his great...</td>\n",
       "      <td>['#golf', '#marriedlife', '#worstfear']</td>\n",
       "      <td>heather_mcg98</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#worstfear</td>\n",
       "      <td>fear</td>\n",
       "      <td>en</td>\n",
       "      <td>[üòÇ, üòÇ, üòÇ, üòÇ]</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26807</th>\n",
       "      <td>1285346329309220865</td>\n",
       "      <td>1595285420000</td>\n",
       "      <td>2020-07-20 17:50:20</td>\n",
       "      <td>better is the sight of the eyes than the wande...</td>\n",
       "      <td>['#god', '#bible', '#wisdom']</td>\n",
       "      <td>SevenShepherd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#wisdom</td>\n",
       "      <td>trust</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27147</th>\n",
       "      <td>1038938243423789056</td>\n",
       "      <td>1536537154000</td>\n",
       "      <td>2018-09-09 18:52:34</td>\n",
       "      <td>leadership leaders singapore delhi goals ican ...</td>\n",
       "      <td>['#leadership', '#leaders', '#singapore', '#de...</td>\n",
       "      <td>eShailendra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#success</td>\n",
       "      <td>trust</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>1158515343637340160</td>\n",
       "      <td>1565046556000</td>\n",
       "      <td>2019-08-05 18:09:16</td>\n",
       "      <td>i am a strong woman because a strong woman rai...</td>\n",
       "      <td>['#mom', '#love', '#thankful', '#raise']</td>\n",
       "      <td>quotes_lives</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>#thankful</td>\n",
       "      <td>joy</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20941</th>\n",
       "      <td>1034190089579114496</td>\n",
       "      <td>1535405106000</td>\n",
       "      <td>2018-08-27 16:25:06</td>\n",
       "      <td>is your anxiety getting the best of you go for...</td>\n",
       "      <td>['#anxiety', '#anxious', '#introverts', '#soli...</td>\n",
       "      <td>proudsolitude</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#anxious</td>\n",
       "      <td>fear</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20386</th>\n",
       "      <td>1188935879345225728</td>\n",
       "      <td>1572299377000</td>\n",
       "      <td>2019-10-28 16:49:37</td>\n",
       "      <td>thanks baton rouge for telling me you were com...</td>\n",
       "      <td>['#pissed']</td>\n",
       "      <td>haileyfaucheaux</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#pissed</td>\n",
       "      <td>anger</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id     created_at                 date  \\\n",
       "28148  1124371022185140224  1556905916000  2019-05-03 12:51:56   \n",
       "23     1224106016524197889  1580684591000  2020-02-02 18:03:11   \n",
       "14399  1011309671808811009  1529949989000  2018-06-25 13:06:29   \n",
       "19427   962439792674865153  1518298502000  2018-02-10 16:35:02   \n",
       "461    1070466884003344386  1544054168000  2018-12-05 18:56:08   \n",
       "6156    979384672873603077  1522338476000  2018-03-29 10:47:56   \n",
       "16934  1127708795118018562  1557701703000  2019-05-12 17:55:03   \n",
       "15124  1021559301696049152  1532393691000  2018-07-23 19:54:51   \n",
       "14493  1009877668198801408  1529608573000  2018-06-21 14:16:13   \n",
       "23201  1160303455212359680  1565472875000  2019-08-10 16:34:35   \n",
       "21250  1073309420791234560  1544731881000  2018-12-13 15:11:21   \n",
       "17010  1137848608483663872  1560119223000  2019-06-09 17:27:03   \n",
       "13055  1216158136748429312  1578789669000  2020-01-11 19:41:09   \n",
       "10011  1056786573914628096  1540792528000  2018-10-29 00:55:28   \n",
       "3102   1112074032499904512  1553974085000  2019-03-30 14:28:05   \n",
       "26807  1285346329309220865  1595285420000  2020-07-20 17:50:20   \n",
       "27147  1038938243423789056  1536537154000  2018-09-09 18:52:34   \n",
       "2584   1158515343637340160  1565046556000  2019-08-05 18:09:16   \n",
       "20941  1034190089579114496  1535405106000  2018-08-27 16:25:06   \n",
       "20386  1188935879345225728  1572299377000  2019-10-28 16:49:37   \n",
       "\n",
       "                                                   tweet  \\\n",
       "28148  realestateagent latoyaforbesgroup latoyalyonel...   \n",
       "23     people are afraid to make a change because the...   \n",
       "14399  black namaste white violent smile writers poet...   \n",
       "19427  at the moment i m trying around with different...   \n",
       "461    thank you riesling always there for me when bo...   \n",
       "6156   strikes again left this outside in the rain ch...   \n",
       "16934  join us for a wonderland tea party with alice ...   \n",
       "15124  the outcome of being without power for three d...   \n",
       "14493  ihearya brave anxiety all shapes sizes gender ...   \n",
       "23201  trust is choosing to make something important ...   \n",
       "21250  driving and you get stopped by every traffic l...   \n",
       "17010  i met a new friend today and she sent me pictu...   \n",
       "13055  how how could you end season like that release...   \n",
       "10011  lmao igotbannedinroblox finally my lil brother...   \n",
       "3102   my husband just confessed to me that his great...   \n",
       "26807  better is the sight of the eyes than the wande...   \n",
       "27147  leadership leaders singapore delhi goals ican ...   \n",
       "2584   i am a strong woman because a strong woman rai...   \n",
       "20941  is your anxiety getting the best of you go for...   \n",
       "20386  thanks baton rouge for telling me you were com...   \n",
       "\n",
       "                                                hashtags         username  \\\n",
       "28148  ['#blessed', '#realestateagent', '#latoyaforbe...  LatoyaUrRealtor   \n",
       "23     ['#people', '#afraid', '#change', '#focus', '#...  MichelleAileene   \n",
       "14399  ['#writers', '#poet', '#writer', '#spokenword'...  stiffmidlefinga   \n",
       "19427  ['#drawing', '#scrapbooking', '#creepy', '#ske...    IICherubinaII   \n",
       "461    ['#wine', '#thankful', '#sweaty', '#riesling',...             NKH3   \n",
       "6156                          ['#angrytweet', '#hermes']          R_Leeee   \n",
       "16934  ['#thekentuckycastle', '#tkcevents', '#castle'...    thecastlepost   \n",
       "15124                          ['#pissed', '#hungrynow']     KeMo_Allen76   \n",
       "14493     ['#ihearya', '#brave', '#anxiety', '#anxious']         mrsroo83   \n",
       "23201       ['#vulnerability', '#trust', '#inspiration']  LeeMichaelWalt1   \n",
       "21250  ['#why', '#thursday', '#thursdaythoughts', '#a...    late_drinkers   \n",
       "17010                               ['#art', '#blessed']       NymphaticM   \n",
       "13055         ['#pissed', '#cliffhanger', '#finalspace']  ellendevenney96   \n",
       "10011           ['#lmao', '#yay', '#igotbannedinroblox']  bsg1623official   \n",
       "3102             ['#golf', '#marriedlife', '#worstfear']    heather_mcg98   \n",
       "26807                      ['#god', '#bible', '#wisdom']    SevenShepherd   \n",
       "27147  ['#leadership', '#leaders', '#singapore', '#de...      eShailendra   \n",
       "2584            ['#mom', '#love', '#thankful', '#raise']     quotes_lives   \n",
       "20941  ['#anxiety', '#anxious', '#introverts', '#soli...    proudsolitude   \n",
       "20386                                        ['#pissed']  haileyfaucheaux   \n",
       "\n",
       "       nlikes  nreplies  nretweets       search emotion lang  \\\n",
       "28148       0         0          0       #trust   trust   en   \n",
       "23          0         0          0      #afraid    fear   en   \n",
       "14399       0         0          0        #hate   anger   en   \n",
       "19427       2         0          0        #fear    fear   en   \n",
       "461         1         0          0    #thankful     joy   en   \n",
       "6156        1         0          0  #angrytweet   anger   en   \n",
       "16934       1         0          1       #happy     joy   en   \n",
       "15124       0         0          0      #pissed   anger   en   \n",
       "14493       1         0          0     #anxious    fear   en   \n",
       "23201       2         0          0       #trust   trust   en   \n",
       "21250       0         0          2       #angry   anger   en   \n",
       "17010       5         0          0     #blessed     joy   en   \n",
       "13055       1         0          0      #pissed   anger   en   \n",
       "10011       5         0          1         #yay     joy   en   \n",
       "3102        9         1          0   #worstfear    fear   en   \n",
       "26807       1         0          1      #wisdom   trust   en   \n",
       "27147       0         0          0     #success   trust   en   \n",
       "2584       18         2          4    #thankful     joy   en   \n",
       "20941       2         0          1     #anxious    fear   en   \n",
       "20386       0         0          0      #pissed   anger   en   \n",
       "\n",
       "                       emoji  len  \n",
       "28148                     []  157  \n",
       "23                        []  189  \n",
       "14399                     []   69  \n",
       "19427                     []  215  \n",
       "461             [üôè, üôè, ü•∂, üî•]  157  \n",
       "6156                      []  208  \n",
       "16934                     []  179  \n",
       "15124  [ü§¶, üèΩ, ‚ôÄ, üò†, ü§¶, üèΩ, ‚ôÄ]   90  \n",
       "14493                     []   89  \n",
       "23201                 [‚ú®, üïä]  142  \n",
       "21250                     []  159  \n",
       "17010                     []  187  \n",
       "13055                    [üò≠]   88  \n",
       "10011                     []   96  \n",
       "3102            [üòÇ, üòÇ, üòÇ, üòÇ]  197  \n",
       "26807                     []  141  \n",
       "27147                     []  154  \n",
       "2584                      []   82  \n",
       "20941                     []  119  \n",
       "20386                     []   84  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('emotion_tweets_cleaned.csv')\n",
    "\n",
    "data['emoji'] = data.tweet.apply(lambda x: cf.extract_emojis(x))\n",
    "# data['tweet'] = data.apply(lambda x: remove_hashtags(x), axis=1)\n",
    "data['tweet'] = data.tweet.apply(lambda x: cf.remove_specific_links(x))\n",
    "data['tweet'] = data.tweet.apply(lambda x: cf.remove_urls(x))\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(lambda x: cf.replace_contractions(x))\n",
    "data['tweet'] = data.tweet.apply(lambda x: cf.remove_punctuation(x))\n",
    "\n",
    "# data['tweet'] = data.apply(lambda x: cf.add_emojis(x), axis=1)\n",
    "\n",
    "data = data.drop(data[data.emotion == 'anger'].sample(6000).index)\n",
    "\n",
    "data = data[data.tweet.apply(lambda x: len(x)) > 60]\n",
    "\n",
    "data['len'] = data['tweet'].apply(lambda s : len(s))\n",
    "\n",
    "\n",
    "data.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preparation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of the cleaned strings: 62\n"
     ]
    }
   ],
   "source": [
    "# Place text into a list of lists, only keywords are included\n",
    "# All the keywords on a n x m list | n = #tweets in dataset m= #wordsxtweet\n",
    "sequences = [x for x in data.tweet]\n",
    "\n",
    "# Tokenize, convert words to numbers\n",
    "# df['tokenizer'] = df.clean_tweet.apply(lambda x: ' '.join(ast.literal_eval(x)))\n",
    "tokenizer = Tokenizer(num_words=20000, lower=True)\n",
    "tokenizer.fit_on_texts(data.tweet)\n",
    "tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "\n",
    "#Padding : Make all inputs the same size\n",
    "maxlen = np.max([len(i) for i in tokenized])\n",
    "print('Max length of the cleaned strings:' , maxlen) \n",
    "X = pad_sequences(tokenized, maxlen=maxlen)\n",
    "\n",
    "# Encode outcome variable\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(data.emotion.unique())\n",
    "y = encoder.transform(data.emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14089 5209 2083\n",
      "14089 5209 2083\n"
     ]
    }
   ],
   "source": [
    "train_keys = [x for x in range(0,len(X)-1)]\n",
    "val_keys = list(np.random.choice(len(X), size=int(len(X)*.25), replace=False))\n",
    "train_keys = list(set(train_keys) - set(val_keys))\n",
    "test_keys = list(np.random.choice(len(X), size=int(len(X)*.1), replace=False))\n",
    "train_keys = list(set(train_keys) - set(test_keys))\n",
    "\n",
    "X_train,X_val,X_test = X[train_keys], X[val_keys],X[test_keys]\n",
    "print(len(X_train),len(X_val),len(X_test))\n",
    "y_train,y_val,y_test = y[train_keys], y[val_keys],y[test_keys]\n",
    "print(len(y_train),len(y_val),len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Define the **LSTM** + **CNN** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = min(tokenizer.num_words, len(tokenizer.word_index) + 1)\n",
    "num_classes = len(data.emotion.unique())\n",
    "embedding_dim = 500\n",
    "lstm_units = 16\n",
    "lstm_dropout = 0.2\n",
    "recurrent_dropout = 0.2\n",
    "spatial_dropout=0.4\n",
    "filters=8\n",
    "kernel_size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(maxlen,))\n",
    "output_layer = Embedding( input_dim=input_dim, output_dim=embedding_dim, input_shape=(maxlen,))(input_layer)\n",
    "output_layer = SpatialDropout1D(spatial_dropout)(output_layer)\n",
    "\n",
    "\n",
    "output_layer = Bidirectional(LSTM(lstm_units, return_sequences=True, dropout=lstm_dropout, recurrent_dropout=recurrent_dropout))(output_layer)\n",
    "output_layer = Conv1D(filters, kernel_size=kernel_size, padding='valid',  kernel_initializer='glorot_uniform')(output_layer)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(output_layer)\n",
    "max_pool = GlobalMaxPooling1D()(output_layer)\n",
    "output_layer = concatenate([avg_pool, max_pool])\n",
    "\n",
    "output_layer = Dense(num_classes, activation='sigmoid')(output_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 63)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 63, 500)      10000000    input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 63, 500)      0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 63, 32)       66176       spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 61, 8)        776         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 8)            0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 8)            0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16)           0           global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            68          concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 10,067,020\n",
      "Trainable params: 10,067,020\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Do the training process with the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
